import math
import numpy as np
import matplotlib.pyplot as plt

from pathlib import Path
import h5py
from tqdm import tqdm
import time
import yaml
import pickle
import torch
import cv2
from collections import deque
import argparse
import sys

from einops import rearrange

from pathlib import Path
current_dir = Path(__file__).parent.resolve()
LOG_DIR = (current_dir / 'logs/').resolve()

from imitate_episodes import make_policy, load_ckpt, make_config
from utils import joint_state_26_to_56

def get_norm_stats(data_path):
    with open(data_path, "rb") as f:
        norm_stats = pickle.load(f)
    return norm_stats

def load_policy(config):
    ckpt_dir = config['ckpt_dir']
    policy_class = config['policy_class']
    policy_config = config['policy_config']
    
    policy = make_policy(policy_class, policy_config)
    policy.cuda()
    
    policy, ckpt_name, epoch = load_ckpt(policy, ckpt_dir, config['resume_ckpt'])
    
    return policy

def normalize_input(state, agentview_rgb, norm_stats, last_action_data=None):
    agentview_rgb = rearrange(agentview_rgb, 'h w c -> c h w')
    image_data = torch.from_numpy(np.stack([agentview_rgb], axis=0)) / 255.0
    qpos_data = (torch.from_numpy(state) - norm_stats["qpos_mean"]) / norm_stats["qpos_std"]
    image_data = image_data.view((1, 1, 3, 224, 224)).float().to(device='cuda')
    state_dim = len(norm_stats["qpos_mean"])
    qpos_data = qpos_data.view((1, state_dim)).float().to(device='cuda') # TODO: change 13 to state_dim

    if last_action_data is not None:
        last_action_data = torch.from_numpy(last_action_data).to(device='cuda').view((1, -1)).to(torch.float)
        qpos_data = torch.cat((qpos_data, last_action_data), dim=1)
    return (qpos_data, image_data)

def cut_img(img):
    assert img.shape[0] == 720 and img.shape[1] == 1280
    lower_img = img[180:, :, :]
    return lower_img

def resize_img(img):
    resized_img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)
    return resized_img

def raw_image_preprocess(image, crop=False):
    if crop:
        img_lower = cut_img(image)
    else:
        img_lower = image.copy()
    img_final = resize_img(img_lower)
    return img_final

def merge_act(actions_for_curr_step, k = 0.01):
    actions_populated = np.all(actions_for_curr_step != 0, axis=1)
    actions_for_curr_step = actions_for_curr_step[actions_populated]

    exp_weights = np.exp(-k * np.arange(actions_for_curr_step.shape[0]))
    exp_weights = (exp_weights / exp_weights.sum()).reshape((-1, 1))
    raw_action = (actions_for_curr_step * exp_weights).sum(axis=0)

    return raw_action

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--eval', action='store_true')
    parser.add_argument('--onscreen_render', action='store_true')
    parser.add_argument('--policy_class', action='store', type=str, help='policy_class, capitalize', required=True)
    parser.add_argument('--batch_size', action='store', type=int, help='batch_size', required=True)
    parser.add_argument('--seed', action='store', type=int, help='seed', required=True)
    parser.add_argument('--num_epochs', action='store', type=int, help='num_epochs', required=True)
    parser.add_argument('--lr', action='store', type=float, help='lr', required=True)
    parser.add_argument('--qpos_noise_std', action='store', default=0, type=float, help='lr', required=False)

    parser.add_argument('--backbone', action='store', type=str, default='resnet18', help='visual backbone, choose from resnet18, resnet34, dino_v2', required=False)
    parser.add_argument('--state_dim', action='store', type=int, default=13, help='state_dim', required=False)
    parser.add_argument('--action_dim', action='store', type=int, default=13, help='action_dim', required=False)
    
    # for ACT
    parser.add_argument('--kl_weight', action='store', type=int, help='KL Weight', required=False)
    parser.add_argument('--chunk_size', action='store', type=int, help='chunk_size', required=False)
    parser.add_argument('--hidden_dim', action='store', type=int, help='hidden_dim', required=False)
    parser.add_argument('--dim_feedforward', action='store', type=int, help='dim_feedforward', required=False)
    parser.add_argument('--temporal_agg', action='store_true')
    parser.add_argument('--save_jit', action='store_true')
    parser.add_argument('--no_wandb', action='store_true')
    parser.add_argument('--resumeid', action='store', default="", type=str, help='resume id', required=False)
    parser.add_argument('--resume_ckpt', action='store', type=str, help='resume ckpt', required=True)
    parser.add_argument('--task-name', action='store', type=str, help='task name', required=True)
    parser.add_argument('--exptid', action='store', type=str, help='experiment id', required=True)
    parser.add_argument('--dataset-path', action='store', type=str, help='path_to_hdf5_dataset', required=True)
    
    parser.add_argument('--saving-interval', action='store', type=int, default=5000, help='saving interval', required=False)
    args = vars(parser.parse_args())

    config = make_config(args)
    
    ckpt_dir = config['ckpt_dir']
    norm_stat_path = Path(ckpt_dir) / "dataset_stats.pkl"
    
    temporal_agg = True
    action_dim = args['action_dim']

    chunk_size = args['chunk_size']
    device = "cuda"
    
    timestamps = 300 # max length of an episode

    norm_stats = get_norm_stats(norm_stat_path)
    policy = load_policy(config)
    policy.cuda()
    policy.eval()

    history_stack = 0
    last_action_queue = None
    last_action_data = None
    
    # TODO: start real robot control
    # TODO: start redis client
    # TODO: real robot interpolate to start pose
    
    # ---

    if temporal_agg:
        all_time_actions = np.zeros([timestamps, timestamps+chunk_size, action_dim])
    else:
        num_actions_exe = chunk_size
    
    try:
        output = None
        act_index = 0
        
        L_pos = np.zeros(56)
        # TODO: define L_pos
        
        last_state = L_pos.copy()
            
        for t in tqdm(range(timestamps)):
            if history_stack > 0:
                last_action_data = np.array(last_action_queue)

            state = last_state.copy()
            
            agentview_rgb = None # replace with getting img from redis server
            agentview_rgb = raw_image_preprocess(agentview_rgb, crop=True)
            
            data = normalize_input(state, agentview_rgb, norm_stats, last_action_data)

            if temporal_agg: # Must be true
                output = policy(*data)[0].detach().cpu().numpy() # (1,chuck_size,action_dim)
                all_time_actions[[t], t:t+chunk_size] = output
                act = merge_act(all_time_actions[:, t])
                
            act = act * norm_stats["action_std"] + norm_stats["action_mean"]

            urdf_action = joint_state_26_to_56(act)
            # TODO: convert urdf_action to real robot action, and send it to the robot
            
            last_state = urdf_action.copy()

    except KeyboardInterrupt:
        
        # TODO: some code
        
        exit()